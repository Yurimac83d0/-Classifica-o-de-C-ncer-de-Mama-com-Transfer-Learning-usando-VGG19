# -*- coding: utf-8 -*-
"""reserva tcc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18TMlSsJpltjcG9-3qDq7ituartrpFl7X
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Diretórios de treinamento e teste
diretorio_treinamento = '/content/drive/MyDrive/Dataset/train'
diretorio_teste = '/content/drive/MyDrive/Dataset/test'

# Dimensões das imagens e outros parâmetros
largura_imagem, altura_imagem = 150, 150
tamanho_lote = 32
epocas = 20

# Carregando a base do modelo VGG-19 sem incluir as camadas densas no topo
base_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(largura_imagem, altura_imagem, 3))

# Congelando as camadas da base do modelo
for layer in base_vgg19.layers:
    layer.trainable = False

# Adicionando camadas densas personalizadas
entrada = Input(shape=(largura_imagem, altura_imagem, 3))
x = base_vgg19(entrada)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
saida = Dense(3, activation='softmax')(x)

modelo = Model(inputs=entrada, outputs=saida)

# Compilando o modelo
modelo.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Pré-processamento e aumento de dados
datagen = ImageDataGenerator(rescale=1./255,
                             shear_range=0.2,
                             zoom_range=0.2,
                             horizontal_flip=True)

gerador_treinamento = datagen.flow_from_directory(
    diretorio_treinamento,
    target_size=(largura_imagem, altura_imagem),
    batch_size=tamanho_lote,
    class_mode='categorical'
)

gerador_teste = datagen.flow_from_directory(
    diretorio_teste,
    target_size=(largura_imagem, altura_imagem),
    batch_size=tamanho_lote,
    class_mode='categorical'
)

# Treinamento do modelo
modelo.fit(
    gerador_treinamento,
    steps_per_epoch=gerador_treinamento.samples // tamanho_lote,
    epochs=epocas,
    validation_data=gerador_teste,
    validation_steps=gerador_teste.samples // tamanho_lote
)

# Salvando o modelo treinado
modelo.save('modelo_cancer_mama_vgg19.keras')

# Caminho para salvar no Google Drive
caminho_modelo = '/content/drive/MyDrive/Dataset/modelo_cancer_mama_vgg19.keras'

# Salvando o modelo treinado no Google Drive
modelo.save(caminho_modelo)

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import numpy as np

# Carregar o modelo treinado
modelo = load_model('modelo_cancer_mama_vgg19.keras')

# Diretório de validação
diretorio_validacao = '/content/drive/MyDrive/Dataset/validation'

# Dimensões das imagens e parâmetros
largura_imagem, altura_imagem = 150, 150
tamanho_lote = 32

# Pré-processamento dos dados de validação
datagen = ImageDataGenerator(rescale=1./255)

# Criar o gerador de dados para validação
gerador_validacao = datagen.flow_from_directory(
    diretorio_validacao,
    target_size=(largura_imagem, altura_imagem),
    batch_size=tamanho_lote,
    class_mode='categorical',
    shuffle=False  # Manter a ordem das imagens
)

# Realizar previsões
predicoes = modelo.predict(gerador_validacao, steps=gerador_validacao.samples // tamanho_lote + 1)

# Decodificar previsões
classe_predita = np.argmax(predicoes, axis=1)

# Obter rótulos verdadeiros a partir do gerador
rótulos_verdadeiros = gerador_validacao.classes

# Gerar o relatório de classificação
relatorio = classification_report(rótulos_verdadeiros, classe_predita, target_names=gerador_validacao.class_indices.keys(), output_dict=True)

# Extrair métricas
precisao = [round(relatorio[classe]['precision'], 3) for classe in relatorio.keys() if classe != 'accuracy']
recall = [round(relatorio[classe]['recall'], 3) for classe in relatorio.keys() if classe != 'accuracy']
f1_score_val = [round(relatorio[classe]['f1-score'], 3) for classe in relatorio.keys() if classe != 'accuracy']
classes = [classe for classe in relatorio.keys() if classe != 'accuracy']

# Adicionar acurácia
acuracia = round(relatorio['accuracy'], 3)

# Plotar o gráfico
fig, ax = plt.subplots(figsize=(10, 6))

bar_width = 0.2
index = np.arange(len(classes))

bar1 = ax.bar(index - bar_width, precisao, bar_width, label='Precisão')
bar2 = ax.bar(index, recall, bar_width, label='Recall')
bar3 = ax.bar(index + bar_width, f1_score_val, bar_width, label='F1-Score')

# Adicionar valores numéricos no topo de cada barra
for bars, metric in zip([bar1, bar2, bar3], [precisao, recall, f1_score_val]):
    for bar, val in zip(bars, metric):
        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{val:.3f}',
                ha='center', va='bottom', fontsize=10)

# Adicionar labels e título
ax.set_xlabel('Classes')
ax.set_ylabel('Valores')
ax.set_title('Métricas de Avaliação por Classe ')
ax.set_xticks(index)
ax.set_xticklabels(classes)
ax.legend()

# Adicionar a acurácia ao gráfico
plt.figtext(0.15, 0.95, f'Acurácia: {acuracia:.3f}', fontsize=12, ha='left')

plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Obter a matriz de confusão
matriz_confusao = confusion_matrix(rótulos_verdadeiros, classe_predita)

# Criar um mapa de calor da matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues', xticklabels=gerador_validacao.class_indices.keys(), yticklabels=gerador_validacao.class_indices.keys())

# Adicionar títulos e labels
plt.title('Matriz de Confusão')
plt.xlabel('Classe Predita')
plt.ylabel('Classe Verdadeira')

# Exibir o gráfico
plt.show()